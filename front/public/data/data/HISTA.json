{
    "Cr\u00e9neau": "Sem 4/Sem 6 Lu 8 h 30 - 11 h 15Sem 6 Lu 8 h 30 - 11 h 15",
    "": "Aucune",
    "Pr\u00e9requis": "Cours de probabilit\u00e9s de premi\u00e8re ann\u00e9e (1PROB) Cours d'optimisation de premi\u00e8re ann\u00e9e (1OPTI) Cours de statistiques de deuxi\u00e8me ann\u00e9e (STAT)",
    "Enseignants responsables": "Badr-Eddine CHERIEF-ABDELLATIF",
    "Equipe enseignante": "El Mahdi KHRIBCH",
    "Objectifs du module": "\u00c0 l'issue de ce module, les \u00e9tudiants sauront : 1. Comprendre les probl\u00e8mes principaux pos\u00e9s par la grande dimension en statistique (\" fl\u00e9au de la dimensionnalit\u00e9 \"), ainsi que les nombreux bienfaits de la grande dimension (\" b\u00e9n\u00e9diction de la dimensionnalit\u00e9 \"). 2. S\u00e9lectionner des mod\u00e8les statistiques pertinents en grande dimension : sparsit\u00e9, structure de type faible rang, choix du type de r\u00e9gularisation. 3. Analyser la performance statistique des principaux estimateurs utilis\u00e9s en grande dimension. 4. Impl\u00e9menter ces m\u00e9thodes \u00e0 l'aide de librairies Python, et \u00e9valuer la qualit\u00e9 des estimateurs entra\u00een\u00e9s.",
    "Programme du module": "0. Introduction et motivation. Pr\u00e9sentation de quelques probl\u00e8mes de g\u00e9om\u00e9trie et de probabilit\u00e9s en grande dimension et du \" fl\u00e9au de la dimensionnalit\u00e9 \". 1. Rappels sur la r\u00e9gression lin\u00e9aire et sur le maximum de vraisemblance. \u00c9tude de la performance de l'estimateur en \" petite \" dimension. 2. Shrinkage & ph\u00e9nom\u00e8ne de Stein. Analyse de la sous-optimalit\u00e9 du maximum de vraisemblance en grande dimension. 3. Syst\u00e8mes lin\u00e9aires ind\u00e9termin\u00e9s et sparsit\u00e9. Introduction \u00e0 la probl\u00e9matique de la s\u00e9lection du mod\u00e8le : principes et th\u00e9orie. 4. Relaxation convexe. D\u00e9finition de la proc\u00e9dure Basis Pursuit et de l'esimateur LASSO. Analyse de transitions de phases pour la Basis Pursuit. 5. \u00c9tude th\u00e9orique d\u00e9taill\u00e9e du LASSO en r\u00e9gression lin\u00e9aire pour diff\u00e9rents objectifs (pr\u00e9diction, estimation, s\u00e9lection de variables). 6. Sur-param\u00e9trisation et sur-apprentissage b\u00e9nin : le cas de la r\u00e9gression lin\u00e9aire. \u00c9tude de la performance de l'interpolant de norme euclidienne minimale et de l'estimateur Ridge. 7. Extensions : R\u00e9gression multivari\u00e9e, Classification supervis\u00e9e, Analyse en Composantes Principales en Grande Dimension, Clustering, Tests multiples.",
    "Modalit\u00e9s": "Quatre s\u00e9ances de travaux pratiques d'1h15 et quatre s\u00e9ances de travaux dirig\u00e9s d'1h15 auront lieu sur les cr\u00e9neaux du cours. Un devoir sera \u00e0 effectuer \u00e0 la maison et \u00e0 rendre \u00e0 mi-parcours, et un projet en groupe sera propos\u00e9 avec une courte soutenance (autour de dix minutes) pendant la derni\u00e8re s\u00e9ance. Le devoir \u00e0 la maison et le projet de groupe devraient repr\u00e9senter entre 10 et 15 heures de travail chacun.",
    "Contr\u00f4le des connaissances - R\u00e8gles de validation du module": "25% de l'\u00e9valuation finale couvrira le devoir \u00e0 rendre \u00e0 mi-parcours, 25% concernera le projet de groupe, et les 50% restants prendront la forme d'un examen final th\u00e9orique d'1h30 le jour de la derni\u00e8re s\u00e9ance.",
    "Documents p\u00e9dagogiques - Bibliographie": "Un polycopi\u00e9 est mis \u00e0 disposition des \u00e9tudiants. Des slides serviront de support de cours et seront fournis au fur et \u00e0 mesure.",
    "Effectif maximal": "Effectif illimit\u00e9",
    "D\u00e9partement de rattachement": "D\u00e9partement Ing\u00e9nierie Math\u00e9matique et Informatique",
    "Nombre de cr\u00e9dits ECTS": "3 cr\u00e9dits ECTS",
    "Mise \u00e0 jour": "01 Septembre 2024",
    "Code": "HISTA"
}